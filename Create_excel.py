
# streamlit run main.py
import os, tempfile, re
from typing import List, Optional
import streamlit as st
import requests  # ä½¿ç”¨ requests æ¨¡çµ„ä¾†å‘¼å« Ollama API
from pdf2image import convert_from_path
from openpyxl import Workbook
from tqdm import tqdm
import json
import base64
import cv2
import numpy as np
import traceback
from PIL import Image
import pdfplumber
import pandas as pd
import openpyxl
from openpyxl.styles import Alignment
from openpyxl.utils.dataframe import dataframe_to_rows

# å°‡è¼¸å…¥çš„é é¢ç¯„åœï¼ˆä¾‹å¦‚ï¼š"1, 3-5, 7"ï¼‰è§£ææˆä¸€å€‹é é¢æ•¸å­—çš„åˆ—è¡¨ï¼ˆä¾‹å¦‚ï¼š[1, 3, 4, 5, 7]ï¼‰
def parse_page_spec(spec: str) -> List[int]:
    if not spec:    
        return []   # if æ²’æœ‰æä¾›é ç¢¼ç¯„åœ, ç›´æ¥è¿”å›ç©ºåˆ—è¡¨
    
    pages: set[int] = set()     # ç”¨é›†åˆä¾†å„²å­˜é ç¢¼, é¿å…é‡è¤‡
    for token in spec.split(","):   #ã€€ä»¥,é€²è¡Œåˆ†å‰²
        token = token.strip()   # å»é™¤æ¯å€‹tokenå‰å¾Œçš„ç©ºç™½å­—ç¬¦

        if not token:   # ifç‚ºç©ºå­—ä¸², è·³é
            continue
        m = re.fullmatch(r"(\d+)-(\d+)", token)     # å˜—è©¦åŒ¹é…é ç¢¼ç¯„åœ
        if m:
            a, b = int(m.group(1)), int(m.group(2))     # æå–é ç¢¼ç¯„åœçš„èµ·å§‹é å’ŒçµæŸé 
            if a > b:   # å¦‚æœèµ·å§‹é æ•¸å¤§æ–¼çµæŸé æ•¸, ä»£è¡¨ä¸æ­£å¸¸, è¦é€²è¡Œäº¤æ›
                a, b = b, a
            if a > 0 and b > 0:
                pages.update(range(a, b + 1))   # ä½¿ç”¨rangeä¾†ç”Ÿæˆé ç¢¼ç¯„åœ
            continue

        if token.isdigit() and int(token) > 0:  # å¦‚æœæ˜¯å–®å€‹é ç¢¼(ex: "6"), å‰‡ç›´æ¥åŠ å…¥é›†åˆ
            pages.add(int(token))
    return sorted(pages)

# PDF è½‰åœ–ç‰‡å‡½å¼
def pdf_to_images(pdf_path: str, dpi: int = 300, pages: Optional[List[int]] = None, base_name: str = "") -> List[str]:
    img_dir = os.path.join(os.getcwd(), "tempfiles_img")
    os.makedirs(img_dir, exist_ok=True)     # å‰µå»ºtempfiles_imgè³‡æ–™å¤¾, è£¡é¢æ”¾pdfæª”è½‰å‡ºä¾†çš„åœ–ç‰‡

    out: List[str] = []
    
    # å¦‚æœæœ‰æŒ‡å®šé æ•¸
    if pages:
        for p in pages:
            for pil in convert_from_path(pdf_path, dpi=dpi, first_page=p, last_page=p):
                pth = os.path.join(img_dir, f"{base_name}_p{p}.png")
                pil.save(pth)
                out.append(pth)
    else:
        for i, pil in enumerate(convert_from_path(pdf_path, dpi=dpi), 1):
            pth = os.path.join(img_dir, f"{base_name}_p{i}.png")
            pil.save(pth)
            out.append(pth)
    return out

# ç”¨ np.fromfile è®€æª”æˆä½å…ƒçµ„ï¼Œå†ç”¨ cv2.imdecode å¾è¨˜æ†¶é«”è§£ç¢¼ã€‚å–ä»£ cv2.write(), ç‚ºäº†èƒ½è®€å–ã€‘ç¬¦è™Ÿ
def cv_imread_any(path, flags=cv2.IMREAD_COLOR):
    data = np.fromfile(path, dtype=np.uint8)
    if data.size == 0:
        return None
    return cv2.imdecode(data, flags)

# åŒæ¨£ç‚ºäº†èƒ½å¯«å…¥ã€‘ç¬¦è™Ÿ
def cv_imwrite_any(path, img):
    ext = os.path.splitext(path)[1]  # e.g. .png / .jpg
    ok, buf = cv2.imencode(ext, img)
    if not ok:
        return False
    buf.tofile(path)
    return True

def preprocess_with_image(image_path: str, write_debug=False) -> str:
    """å¼·åŒ–è¡¨æ ¼ç·šæ¢ã€å»å™ªã€äºŒå€¼åŒ–ã€deskewï¼Œå›å‚³è™•ç†å¾Œå½±åƒè·¯å¾‘"""
    img = cv_imread_any(image_path)
    if img is None:
        return image_path  # è®€ä¸åˆ°å°±åŸåœ–

    # 1) ç°éš + å°æ¯”å¢å¼·
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    gray = clahe.apply(gray)

    gray = cv2.GaussianBlur(gray, (5, 5), 0)    # é«˜æ–¯æ¨¡ç³Šä¾†å»é™¤å™ªé»ï¼Œä¿è­·ç´°ç¯€

    # 2) è‡ªé©æ‡‰äºŒå€¼åŒ–ï¼ˆå°æƒæä»¶è¼ƒç©©ï¼‰
    bin_img = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 31, 15)
    # è®“ç·šæ¢ç‚ºé»‘ï¼ŒèƒŒæ™¯ç™½
    bin_inv = cv2.bitwise_not(bin_img)

    horiz_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))   # èª¿å¤§åŠ ç²—æ°´å¹³æ–¹å‘çš„ç·šæ¢
    vert_kernel  = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15))   # èª¿å¤§åŠ ç²—å‚ç›´æ–¹å‘çš„ç·šæ¢

    horiz = cv2.erode(bin_inv, horiz_kernel, iterations=1)  # æ°´å¹³ç·šéƒ¨åˆ†, horizon
    horiz = cv2.dilate(horiz, horiz_kernel, iterations=2)

    vert = cv2.erode(bin_inv, vert_kernel, iterations=1)    # å‚ç›´ç·šéƒ¨åˆ†, vertical
    vert = cv2.dilate(vert, vert_kernel, iterations=2)

    grid = cv2.add(horiz, vert)

    # 5) é€²ä¸€æ­¥åŠ ç²—æ ¼ç·šï¼Œè®“ç¼ºå…§ç·š=åˆä½µå„²å­˜æ ¼æ›´æ˜é¡¯
    thick_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
    grid_thick = cv2.dilate(grid, thick_kernel, iterations=1)
    st.image(grid_thick, caption="å¼·åŒ–å¾Œçš„æ ¼ç·š", channels="GRAY")

    # 6) èˆ‡åŸäºŒå€¼å½±åƒåˆæˆï¼Œä¿ç•™æ–‡å­—çš„åŒæ™‚å¯ä»¥å¼·åŒ–æ ¼ç·š
    merged = cv2.bitwise_or(bin_img, cv2.bitwise_not(grid_thick))

    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    merged = clahe.apply(merged)

    # 7) ä¸Šæ¡æ¨£è®“å°å­—ã€ç´°ç·šæ›´æ¸…æ¥š
    merged = cv2.resize(merged, None, fx=1.2, fy=1.2, interpolation=cv2.INTER_CUBIC)

    # 8) å¦‚æœéœ€è¦ï¼Œé€™è£¡å¯ä»¥åŠ å¼·æ–‡å­—é‚Šç·£ï¼ˆéŠ³åŒ–ï¼‰
    # ä½¿ç”¨ Laplacian é‚Šç·£æª¢æ¸¬ä¾†éŠ³åŒ– 
    laplacian = cv2.Laplacian(merged, cv2.CV_64F)
    laplacian = cv2.convertScaleAbs(laplacian)
    sharp = cv2.addWeighted(merged, 1.5, laplacian, -0.5, 0)
    merged = sharp

    # 8) è¼¸å‡º
    root, ext = os.path.splitext(image_path)
    out_path = f"{root}_pre{ext}"

    cv_imwrite_any(out_path, merged)
    if write_debug:
        dbg_path = f"{root}_grid{ext}"
        cv_imwrite_any(dbg_path, grid_thick)

    return out_path

def OCR_process_pdf(pdf_path, base_name, wb, page_num):
    
    with pdfplumber.open(pdf_path) as pdf:
        page = pdf.pages[page_num - 1]  # å‡è¨­æ˜¯è™•ç†ç¬¬ä¸€é 
        tables = page.extract_tables()

    for idx, table in enumerate(tables):
        if not table:  # é¿å…ç©ºè¡¨æ ¼
            continue

        df = pd.DataFrame(table[1:], columns=table[0])

        sheet_title = f"{base_name}_page{page_num}_table{idx+1}"
        ws = wb.create_sheet(title=sheet_title[:31])  # Excel sheet åç¨±ä¸èƒ½è¶…é 31 å­—å…ƒ

        for r in dataframe_to_rows(df, index=False, header=True):
            ws.append(r)

        # æª¢æŸ¥ä¸¦åˆä½µç©ºå„²å­˜æ ¼
        for col in range(1, len(df.columns) + 1):
            row = 2
            while row <= len(df) + 1:
                current_cell = ws.cell(row=row, column=col)
                if current_cell.value is not None:
                    start_row = row
                    while row + 1 <= len(df) + 1 and ws.cell(row=row + 1, column=col).value is None:
                        row += 1
                    if row > start_row:
                        ws.merge_cells(start_row=start_row, start_column=col, end_row=row, end_column=col)
                        merged_cell = ws.cell(row=start_row, column=col)
                        merged_cell.alignment = Alignment(vertical='top', horizontal='left')
                row += 1
    return wb


# ---- Ollama å‘¼å«ï¼šå›å‚³ JSONæ ¼å¼ï¼Œç„¡è¡¨æ ¼æ™‚return ç©ºé™£åˆ— ----
def process_image_with_ollama(image_path: str, ollama_host, model_name, temperature: float = 0.0, top_p: float = 0.95) -> dict:
    try:
        with open(image_path, "rb") as f:
            img_data = f.read()
            b64 = base64.b64encode(img_data).decode("utf-8")

        url = f"{ollama_host}/api/generate"
        payload = {
            "model": model_name,
            "prompt":   """ Please convert the following table into JSON format, following these steps:
                            1. Cell values:
                            Each cell's content should be stored in the "value" field of the corresponding cell.

                            2. Handling merged cells:
                            Horizontal merges (colspan): If a cell spans across multiple columns, use the colspan attribute to indicate how many columns it spans.
                            Vertical merges (rowspan): If a cell spans across multiple rows, use the rowspan attribute to indicate how many rows it spans.
                            Unmerged cells: If a cell is not merged (i.e., rowspan=1 and colspan=1), only include the value field and do not include rowspan or colspan attributes.
                            Example: If a cell spans two rows, it should appear as:
                            {"value": "cell content", "rowspan": 2}
                            If a cell is unmerged, it should just include:
                            {"value": "cell content"}

                            3. How to detect colspan and rowspan:
                            Rowspan: This is determined by counting the number of black lines on the left and right sides of the cell. If a cell has a maximum of n black lines on its left and right sides, then its rowspan will be n + 1.
                            Colspan: This is determined by counting the number of black lines on the top and bottom sides of the cell. If a cell has a maximum of n black lines on its top and bottom sides, then its colspan will be n + 1.

                            4. Please note that if a cell contains a list (e.g., "1. First item", "2. Second item", etc.), 
                            the entire list should remain in the same cell and not be split into separate cells.

                            5. Please strictly generate content based only on the visible data in the image. Do not add any inferred or missing information that is not shown in the image. 
                            If you cannot determine something from the image, do not make assumptions or provide explanations. Only include the content that is clearly visible in the image.

                            6. Please ensure that the data in each cell is correctly converted and includes all visible content.
                               Avoid omitting any data, even if it seems like a small detail. For each cell's content, it must be fully converted into the value field.

                            7. Output format:
                            Here is an example format. Please strictly follow this format, adjusting the row, column numbers and value based on the actual data:
                            {
                                "tables": [
                                    {
                                    "rows": [
                                        [
                                        {"value": "data1", "colspan": 2},
                                        {"value": "data2"}
                                        ],
                                        [
                                        {"value": "data3", "colspan": 3, "rowspan": 4},
                                        {"value": "data4"}
                                        ]
                                    ]
                                    }
                                ]
                            }

                            Please ensure the format is strictly followed, using the rowspan and colspan attributes correctly for merged cells, and only the value field for unmerged cells.
                            """.strip(),
            "images": [b64],
            "stream": False,
            "format": "json",
            "options": {
                "temperature": temperature,
                "top_p": top_p
            }
        }
        

        r = requests.post(url, json=payload)
        if r.status_code != 200:
            error_message = f"HTTP éŒ¯èª¤: {r.status_code}\nå›æ‡‰å…§å®¹: {r.text}"
            st.error(f"Ollama API éŒ¯èª¤: {error_message}")
            print(f"è©³ç´°éŒ¯èª¤: {error_message}")
            return {"tables": []}

        resp = r.json()     # å°‡é€™æ®µç´”æ–‡å­—å­—ä¸²è½‰æˆPythonçš„å­—å…¸
        raw = resp.get("response", "")      # modelæœƒæœ‰å…¶ä»–çš„outputè³‡è¨Š, åªæ“·å–responseéƒ¨åˆ†
        # print(f"LLM å›å‚³çš„åŸå§‹å›æ‡‰: {raw}")     # debugging line

        # å…è¨± response ç‚º dict æˆ– str
        obj = None
        if isinstance(raw, dict):
            obj = raw
        elif isinstance(raw, str):
            s = raw.strip()
            # å»é™¤ ```json ... ``` åœæ¬„
            if s.startswith("```"):
                s = re.sub(r"^```(?:json)?\s*|\s*```$", "", s, flags=re.S)
            # å–å‡ºç¬¬ä¸€æ®µ {...} ä»¥é˜²æ¨¡å‹å‰å¾Œå¤šå­—
            m = re.search(r"\{[\s\S]*\}", s)
            if m:
                s = m.group(0)
            obj = json.loads(s)
        else:
            # æŸäº›æ¨¡å‹å¯èƒ½æ”¾åœ¨å…¶ä»–æ¬„ä½
            for k in ("message", "content", "text"):
                v = resp.get(k)
                if isinstance(v, dict):
                    obj = v
                    break
                if isinstance(v, str):
                    s = v.strip()
                    if s.startswith("```"):
                        s = re.sub(r"^```(?:json)?\s*|\s*```$", "", s, flags=re.S)
                    m = re.search(r"\{[\s\S]*\}", s)
                    if m:
                        s = m.group(0)
                    obj = json.loads(s)
                    break

        # å‹åˆ¥èˆ‡éµå¥å…¨æ€§æª¢æŸ¥
        if isinstance(obj, dict) and isinstance(obj.get("tables", []), list):
           # å¦‚æœæœ‰è¡¨æ ¼ï¼Œè¿”å›è¡¨æ ¼è³‡æ–™
            tables = obj.get("tables", [])
            return {"tables": tables}
        return {"tables": []}
    except Exception as e:
        error_message = traceback.format_exc()
        print(f"éŒ¯èª¤åŸå› : {error_message}")  # æˆ–è€…ä½¿ç”¨ logging æ¨¡çµ„ä¾†è¨˜éŒ„
        return {"tables": []}
    
# è™•ç†åˆä½µå„²å­˜æ ¼ä¸¦ç”¢å‡ºexcelæª”
def process_and_export_tables(preprocess_files, ollama_url, selected_model, base_name, page_spec, output_path):
    # åˆå§‹åŒ– Excel å·¥ä½œç°¿å’Œé€²åº¦æ¢
    wb = Workbook()
    log_ws = wb.active
    log_ws.title = "log"
    added_any = False
    progress_bar = st.progress(0)  # åˆå§‹åŒ–é€²åº¦æ¢
    total_images = len(preprocess_files)

    for i, img_path in enumerate(preprocess_files, 1):
        img = cv_imread_any(img_path)  # å…ˆè®€å–åœ–ç‰‡
        if img is None:
            st.warning(f"ç„¡æ³•è®€å–åœ–ç‰‡: {img_path}")
            continue

        result = process_image_with_ollama(img_path, ollama_url, selected_model)
        tables = result.get("tables", [])
        if tables:
            if not added_any:
                wb.remove(log_ws)
                added_any = True

            # é€ä¸€è™•ç†æ¯å€‹è¡¨æ ¼
            for j, table in enumerate(tables, 1):
                data = table.get("rows", [])
                sheet_title = f"{base_name}_page{page_spec[i-1]}_table{j}"
                ws = wb.create_sheet(title=sheet_title[:31])

                occupied = set()  # {(r, c)} è¢« row/colspan ä½”ç”¨çš„ä½ç½®
                row_height = img.shape[0] // len(data)
                col_width = img.shape[1] // len(data[0])

                for r_idx, row in enumerate(data, start=1):
                    c_idx = 1
                    for cell in row:
                        if isinstance(cell, dict):
                            value = cell.get("value", "")   # è¡¨æ ¼å…§çš„å€¼
                            rowspan = int(cell.get("rowspan", 1))   # é è¨­ç‚º1
                            colspan = int(cell.get("colspan", 1))
                        else:
                            value, rowspan, colspan = cell, 1, 1

                        # è·³éè¢«ä¸Šä¸€åˆ— rowspan ä½”ç”¨çš„ä½ç½®
                        while (r_idx, c_idx) in occupied:
                            c_idx += 1

                        ws.cell(r_idx, c_idx, value)
                        print(f"Row {r_idx}, Col {c_idx}, Value={value}, Rowspan={rowspan}, Colspan={colspan}")     # debugging line

                        # ç¹ªè£½æ¡†ç·š
                        start_point = (c_idx * col_width, r_idx * row_height)
                        end_point = ((c_idx + colspan) * col_width, (r_idx + rowspan) * row_height)
                        img = cv2.rectangle(img, start_point, end_point, (0, 0, 255), 2)

                        # è™•ç†åˆä½µå„²å­˜æ ¼ï¼Œä¸¦ç¢ºä¿å»¶ä¼¸å„²å­˜æ ¼çš„å€¼
                        if rowspan > 1 or colspan > 1:
                            # å°‡å¼„å¥½çš„å„²å­˜æ ¼é€²è¡Œåˆä½µ
                            ws.merge_cells(
                                start_row=r_idx, start_column=c_idx,
                                end_row=r_idx + rowspan - 1, end_column=c_idx + colspan - 1
                            )

                            # æ¨™è¨˜ä½”ä½ï¼ˆå·¦ä¸Šè§’é™¤å¤–ï¼‰
                            for rr in range(r_idx, r_idx + rowspan):
                                for cc in range(c_idx, c_idx + colspan):
                                    if not (rr == r_idx and cc == c_idx):
                                        occupied.add((rr, cc))

                        c_idx += colspan
        progress_bar.progress(i / total_images)  # æ›´æ–°é€²åº¦æ¢

    # å„²å­˜ Excel æª”æ¡ˆ
    if not added_any:
        log_ws["A1"] = "No tables were extracted."  # å¦‚æœæ˜¯ç©ºçš„è©±, å°±åœ¨A1æ¬„ä½å¡«å…¥ No tables were extracted

    wb.save(output_path)
    st.success(f"å·²æˆåŠŸå°‡è¡¨æ ¼åŒ¯å‡ºåˆ° Excel: {output_path}")
    print(f"å·²æˆåŠŸå°‡è¡¨æ ¼åŒ¯å‡ºåˆ° Excel: {output_path}")
    st.download_button("ä¸‹è¼‰ Excel", data=open(output_path, "rb").read(), file_name=f"{base_name}_tables_{page_spec}.xlsx")

# ---------------- Streamlit UI ----------------
def main():
    Image.MAX_IMAGE_PIXELS = None  # å–æ¶ˆåƒç´ æ•¸é‡é™åˆ¶
    ollama_url = "http://172.20.5.116:11434"
    st.set_page_config(page_title="PDF è¡¨æ ¼è¾¨è­˜ä¸¦åŒ¯å‡ºexcel", page_icon="ğŸ’¬", layout="centered")     # page_titleæŒ‡çš„æ˜¯ä¸Šæ–¹é é¢çš„åç¨±
    st.title("PDF è¡¨æ ¼è¾¨è­˜ä¸¦åŒ¯å‡ºexcel")
    use_LLM = st.checkbox("**PDFæª”æ˜¯å¦ç‚ºä¸å¯è¤‡è£½æ–‡å­—**", value=True)
    if use_LLM:
        model_options = ["qwen2.5vl:7b", "qwen2.5vl:32b", "qwen2.5vl:72b", "gemma3:27b", "mistral-small3.2:24b", "llama4:16x17b", "granite3.2-vision:2b", "llava:34b", "llama3.2-vision:90b", "llava-llama3:8b"]
        selected_model = st.selectbox("é¸æ“‡ LLM æ¨¡å‹", model_options, index=0)
        uploaded_file = st.file_uploader("ä¸Šå‚³ PDF æª”æ¡ˆ", type=["pdf"])
        
        with st.expander("**è¨­å®šåœ–ç‰‡åƒæ•¸**"):
            dpi = st.slider("**è¨­å®š DPI (è§£æåº¦)**", 100, 1400, 300)
            preprocess_option = st.checkbox("**å°åœ–ç‰‡é€²è¡Œå‰è™•ç†**", value=True)
            page_spec = st.text_input("**æŒ‡å®šé ç¢¼ (ä¾‹å¦‚ 1,3-5,7)**", "")
    else:
        uploaded_file = st.file_uploader("ä¸Šå‚³ PDF æª”æ¡ˆ", type=["pdf"])
        page_spec = st.text_input("**æŒ‡å®šé ç¢¼ (ä¾‹å¦‚ 1,3-5,7)**", "")

    if uploaded_file:
        pages = parse_page_spec(page_spec)
        st.info(f"å°‡è™•ç†çš„é ç¢¼: {pages if pages else 'å…¨éƒ¨'}")
        
        if st.button("é–‹å§‹è™•ç†"):
            # å°‡ä¸Šå‚³çš„ PDF å¯«åˆ°æš«å­˜æª”
            pdf_dir = os.path.join(os.getcwd(), "tempfiles_pdf")
            os.makedirs(pdf_dir, exist_ok=True)

            # PDF â†’ åœ–ç‰‡
            pdf_filename = os.path.basename(uploaded_file.name)
            end_index = pdf_filename.find("ã€‘")  # å–å¾—ã€‘çš„ä½ç½®
            if end_index != -1:
                base_name = pdf_filename[:end_index + 1]  # åŒ…å«ã€‘ç¬¦è™Ÿ
            else:
                base_name = pdf_filename[:5]  # æ²’æœ‰ã€‘å°±è®€å‰5å€‹
            # print(base_name)  # debugging line
            
            tmp_pdf_path = os.path.join(pdf_dir, f"{base_name}_uploaded.pdf")
            output_dir = os.path.join(os.getcwd(), "Excel_Output")  # æ”¾åœ¨Excel_Outputå…§
            os.makedirs(output_dir, exist_ok=True)
            output_path = os.path.join(output_dir, f"{base_name}_tables_page{page_spec}.xlsx")

            if use_LLM:
                with open(tmp_pdf_path, "wb") as tmp_pdf:
                    tmp_pdf.write(uploaded_file.read())
                try:
                    with st.spinner("æ­£åœ¨å°‡ PDF è½‰æˆåœ–ç‰‡..."):

                        image_files = pdf_to_images(tmp_pdf_path, dpi=dpi, pages=pages, base_name=base_name)
                        st.success(f"å…±ç”¢ç”Ÿ {len(image_files)} å¼µåœ–ç‰‡")
                        if image_files:
                            st.info("ä»¥ä¸‹æ˜¯è½‰æ›å¾Œçš„ PDF åœ–ç‰‡: ")
                            for img_path in image_files:
                                st.image(img_path)

                        preprocess_files = []
                        if image_files:
                            if preprocess_option:
                                with st.spinner("æ­£åœ¨é€²è¡Œåœ–ç‰‡å‰è™•ç†..."):
                                    for img_path in image_files:
                                        proc = preprocess_with_image(img_path)
                                        preprocess_files.append(proc)   # åŠ å…¥åˆ°
                                    st.success("å‰è™•ç†å®Œæˆ! ä»¥ä¸‹æ˜¯å‰è™•ç†å¾Œçš„åœ–ç‰‡:")
                                    for p in preprocess_files:
                                        st.image(p)
                                        st.write(f"è™•ç†å¾Œåœ–ç‰‡è·¯å¾‘: {p}")
                            else:
                                preprocess_files = image_files  # ä¸é€²è¡Œå‰è™•ç†ï¼Œç›´æ¥ä½¿ç”¨è½‰æ›çš„åœ–ç‰‡
                except Exception as e:
                    st.error(f"è™•ç†éç¨‹å‡ºç¾éŒ¯èª¤: {e}")

                try:
                    with st.spinner("æ­£åœ¨è™•ç†è¡¨æ ¼..."):
                        process_and_export_tables(preprocess_files, ollama_url, selected_model, base_name, page_spec, output_path)   # å‘¼å« Ollama é€²è¡Œè¡¨æ ¼è¾¨è­˜


                except Exception as e:
                    st.error(f"è™•ç†éç¨‹å‡ºç¾éŒ¯èª¤: {e}")
                finally:
                    # åˆªé™¤æš«å­˜çš„ PDF æª”æ¡ˆ
                    if os.path.exists(tmp_pdf_path):
                        os.remove(tmp_pdf_path)
                        st.info("æš«å­˜çš„ PDF æª”æ¡ˆå·²åˆªé™¤")
            else:
                with st.spinner("ç”¨OCRæ–¹å¼å°‡PDFè½‰æˆè¡¨æ ¼..."):
                    with open(tmp_pdf_path, "wb") as tmp_pdf:
                        tmp_pdf.write(uploaded_file.read())
                    wb = Workbook()
                    wb.remove(wb.active)
                    for page in pages:
                        wb = OCR_process_pdf(pdf_path=tmp_pdf_path, wb=wb, base_name=base_name, page_num=page)

                    wb.save(output_path)
                    st.success(f"OCRè™•ç†å®Œæˆ, å·²æˆåŠŸå°‡è¡¨æ ¼åŒ¯å‡ºåˆ°: {output_path}")
                    print(f"OCRè™•ç†å®Œæˆ, å·²æˆåŠŸå°‡è¡¨æ ¼åŒ¯å‡ºåˆ°: {output_path}")

                    if os.path.exists(tmp_pdf_path):
                        os.remove(tmp_pdf_path)
                        st.info("æš«å­˜çš„ PDF æª”æ¡ˆå·²åˆªé™¤")
if __name__ == "__main__":
    main()

